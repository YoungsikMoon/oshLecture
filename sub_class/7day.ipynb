{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6day 숙제 (오답 ㅠㅠ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이토치로 아래 데이터로 선형회귀를 구현하세요,\n",
    "\n",
    "비트코인, 솔라나, 도지코인 ,리플 ,페페코인 의\n",
    "[해당코인전일가(X1) 해당코인저가(X2) 해당코인고가(X3)  NVIDIA현재주가(X4)]\n",
    "\n",
    "현재가(Y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)\n",
    "# 전일종가, 당일저가, 당일고가, 앤비디아주가\n",
    "BITCOIN = [82043000, 81351000, 83825000, 181939]\n",
    "SOLANA = [196800, 196300, 205800, 181939]\n",
    "DOZICOIN = [152, 150, 156, 181939]\n",
    "RIPPLE = [610, 608, 622, 181939]\n",
    "PEPECOIN = [0.02, 0.02, 0.02, 181939]\n",
    "\n",
    "x_train = torch.FloatTensor([[BITCOIN],[SOLANA],[DOZICOIN],[RIPPLE],[PEPECOIN]])\n",
    "y_train = torch.FloatTensor([[82601000], [202200], [153], [621], [0.02]])\n",
    "\n",
    "\n",
    "W = torch.zeros(4, requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "optimizer = optim.SGD([W, b], lr=0.01)\n",
    "\n",
    "epochs = 100\n",
    "for epoch in range(epochs + 1):\n",
    "    optimizer.zero_grad()\n",
    "    # 선형회귀 모델\n",
    "    predict = x_train * W + b\n",
    "    # cost 계산 (Mean Square Error)\n",
    "    cost = torch.mean((predict - y_train) ** 2)\n",
    "    # cost로 모델 개선\n",
    "    cost.backward() # cost를 기반으로 미분 계산\n",
    "    optimizer.step() # 오차역전파법 실행\n",
    "    # 100번마다 로그 출력\n",
    "    if epoch % 100 == 0:\n",
    "        print(\n",
    "            f'Epoch {epoch:4d}/{epochs} W: {W[0]}, {W[1]}, {W[2]} {W[3]} b: {b.item():.3f} Cost: {cost.item():.6f}'\n",
    "            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7day 숙제 (오답 ㅠㅠ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "저번 숙제에 이어서 RobustScaler로 전처리 활용하세요.\n",
    "\n",
    "미니 배치 사이즈 2로 학습하는걸로 코드를 짜주세요.\n",
    "\n",
    "이번에는 챗지피티를 허용합니다. \n",
    "\n",
    "다만 각 줄 주석을 달아와주시길 바랍니다.\n",
    "\n",
    "다음 주 월요일 시간에 리뷰 및 MLP 수업 나가도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/100 W: 0.0, 0.0, 0.0 0.0 b: 331215.844 Cost: 1364593116971008.000000\n",
      "Epoch  100/100 W: 0.0, 0.0, 0.0 0.0 b: 14408436.000 Cost: 1095156866482176.000000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# 랜덤 시드 설정 (재현성을 위해)\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# 가상화폐 데이터 정의\n",
    "BITCOIN = [82043000, 81351000, 83825000, 181939]  # BITCOIN 데이터\n",
    "SOLANA = [196800, 196300, 205800, 181939]  # SOLANA 데이터\n",
    "DOZICOIN = [152, 150, 156, 181939]  # DOZICOIN 데이터\n",
    "RIPPLE = [610, 608, 622, 181939]  # RIPPLE 데이터\n",
    "PEPECOIN = [0.02, 0.02, 0.02, 181939]  # PEPECOIN 데이터\n",
    "\n",
    "# 로버스트 스케일러 적용\n",
    "scaler = RobustScaler()\n",
    "x_train = torch.FloatTensor([ # X 데이터\n",
    "    scaler.fit_transform([BITCOIN]),  # BITCOIN 데이터 정규화\n",
    "    scaler.fit_transform([SOLANA]),   # SOLANA 데이터 정규화\n",
    "    scaler.fit_transform([DOZICOIN]), # DOZICOIN 데이터 정규화\n",
    "    scaler.fit_transform([RIPPLE]),   # RIPPLE 데이터 정규화\n",
    "    scaler.fit_transform([PEPECOIN])  # PEPECOIN 데이터 정규화\n",
    "])\n",
    "y_train = torch.FloatTensor([[82601000], [202200], [153], [621], [0.02]])  # Y 데이터\n",
    "\n",
    "# 모델 파라미터 초기화\n",
    "W = torch.zeros(4, requires_grad=True)  # 가중치 초기화 (4개)\n",
    "b = torch.zeros(1, requires_grad=True)  # 편향 초기화 (1개)\n",
    "\n",
    "# 옵티마이저 정의\n",
    "optimizer = optim.SGD([W, b], lr=0.01)  # 확률적 경사 하강법(SGD) 사용\n",
    "\n",
    "# 모델 학습\n",
    "epochs = 100\n",
    "\n",
    "# 미니배치 크기 설정\n",
    "batch_size = 2\n",
    "\n",
    "for epoch in range(epochs + 1):\n",
    "    for i in range(0, len(x_train), batch_size):\n",
    "        batch_x = x_train[i:i+batch_size]  # 미니배치 입력 데이터\n",
    "        batch_y = y_train[i:i+batch_size]  # 미니배치 출력 데이터\n",
    "        \n",
    "        optimizer.zero_grad()  # 옵티마이저의 기울기 초기화\n",
    "        \n",
    "        # 선형 회귀 모델\n",
    "        predict = batch_x * W + b  # 예측값 계산\n",
    "        \n",
    "        # 비용 함수 계산 (Mean Square Error)\n",
    "        cost = torch.mean((predict - batch_y) ** 2)  # 실제값과 예측값 차이의 제곱 평균\n",
    "        \n",
    "        # 역전파를 통한 모델 업데이트\n",
    "        cost.backward()  # 비용 함수에 대한 기울기 계산\n",
    "        optimizer.step()  # 옵티마이저를 통해 가중치와 편향 업데이트\n",
    "    \n",
    "    # 100번째 에폭마다 로그 출력\n",
    "    if epoch % 100 == 0:\n",
    "        print(\n",
    "            f'Epoch {epoch:4d}/{epochs} W: {W[0]}, {W[1]}, {W[2]} {W[3]} b: {b.item():.3f} Cost: {cost.item():.6f}'\n",
    "        )\n",
    "\n",
    "\n",
    "# 질문 포인트\n",
    "# 왜 W가 0.0 일까?\n",
    "# 미니배치는 정확히 뭘까?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oshLecture",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
